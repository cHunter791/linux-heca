/*
 * Benoit Hudzia <benoit.hudzia@sap.com> 2013 (c)
 */
#include <linux/rcupdate.h>
#include <linux/errno.h>
#include <linux/pagemap.h>

#include "hecatonchire.h"
#include "hproc.h"
#include "hutils.h"


#include "base.h"
#include "task.h"
#include "pull.h"
#include "trace.h"
#include "ops.h"
#include "push.h"
#include "conn.h"

#define HPROCS_KSET             "process"
#define MRS_KSET                "memory_regions"

#define to_hproc(p)             container_of(s, struct heca_process, kobj)
#define to_hproc_attr(pa)       container_of(pa, struct hproc_attr, attr)

static void destroy_hproc_mrs(struct heca_process *hproc);

int deregister_hspace(__u32 hspace_id)
{
        struct heca_module_state *heca_state = get_heca_module_state();
        int ret = 0;
        struct heca_space *hspace;
        struct list_head *curr, *next;

        heca_printk(KERN_DEBUG "<enter> hspace_id=%d", hspace_id);
        list_for_each_safe (curr, next, &heca_state->hspaces_list) {
                hspace = list_entry(curr, struct heca_space, hspace_ptr);
                if (hspace->hspace_id == hspace_id)
                        remove_hspace(hspace);
        }

        destroy_hcm_listener(heca_state);
        heca_printk(KERN_DEBUG "<exit> %d", ret);
        return ret;
}

int register_hspace(struct hecaioc_hspace *hspace_info)
{
        struct heca_module_state *heca_state = get_heca_module_state();
        int rc;

        heca_printk(KERN_DEBUG "<enter>");

        if ((rc = create_hcm_listener(heca_state,
                                        hspace_info->local.sin_addr.s_addr,
                                        hspace_info->local.sin_port))) {
                heca_printk(KERN_ERR "create_hcm %d", rc);
                goto done;
        }

        if ((rc = create_hspace(hspace_info->hspace_id))) {
                heca_printk(KERN_ERR "create_hspace %d", rc);
                goto done;
        }

done:
        if (rc)
                deregister_hspace(hspace_info->hspace_id);
        heca_printk(KERN_DEBUG "<exit> %d", rc);
        return rc;
}

inline int is_hproc_local(struct heca_process *hproc)
{
        return !!hproc->mm;
}

static inline int grab_hproc(struct heca_process *hproc)
{
#if !defined(CONFIG_SMP) && defined(CONFIG_TREE_RCU)
# ifdef CONFIG_PREEMPT_COUNT
        BUG_ON(!in_atomic());
# endif
        BUG_ON(atomic_read(&hproc->refs) == 0);
        atomic_inc(&hproc->refs);
#else
        if (!atomic_inc_not_zero(&hproc->refs))
                return -1;
#endif
        return 0;
}

static struct heca_process *_find_hproc_in_tree(
                struct radix_tree_root *root, unsigned long hproc_id)
{
        struct heca_process *hproc;
        struct heca_process **hprocp;

        rcu_read_lock();
repeat:
        hproc = NULL;
        hprocp = (struct heca_process **) radix_tree_lookup_slot(root,
                        (unsigned long) hproc_id);
        if (hprocp) {
                hproc = radix_tree_deref_slot((void**) hprocp);
                if (unlikely(!hproc))
                        goto out;
                if (radix_tree_exception(hproc)) {
                        if (radix_tree_deref_retry(hproc))
                                goto repeat;
                }

                if (grab_hproc(hproc))
                        goto repeat;

        }

out:
        rcu_read_unlock();
        return hproc;
}

inline struct heca_process *find_hproc(struct heca_space *hspace, u32 hproc_id)
{
        return _find_hproc_in_tree(&hspace->hprocs_tree_root,
                        (unsigned long) hproc_id);
}

inline struct heca_process *find_local_hproc_in_hspace(
                struct heca_space *hspace, struct mm_struct *mm)
{
        return _find_hproc_in_tree(&hspace->hprocs_mm_tree_root,
                        (unsigned long) mm);
}

inline struct heca_process *find_local_hproc_from_mm(struct mm_struct *mm)
{
        struct heca_module_state *mod = get_heca_module_state();

        return (likely(mod)) ?
                _find_hproc_in_tree(&mod->mm_tree_root, (unsigned long) mm) :
                NULL;
}

static int insert_hproc_to_radix_trees(struct heca_module_state *heca_state,
                struct heca_space *hspace, struct heca_process *new_hproc)
{
        int r;

preload:
        r = radix_tree_preload(GFP_HIGHUSER_MOVABLE & GFP_KERNEL);
        if (r) {
                if (r == -ENOMEM) {
                        heca_printk(KERN_ERR "radix_tree_preload: ENOMEM retrying ...");
                        mdelay(2);
                        goto preload;
                }
                heca_printk(KERN_ERR "radix_tree_preload: failed %d", r);
                goto out;
        }


        spin_lock(&heca_state->radix_lock);
        r = radix_tree_insert(&hspace->hprocs_tree_root,
                        (unsigned long) new_hproc->hproc_id, new_hproc);
        if (r)
                goto unlock;

        if (is_hproc_local(new_hproc)) {
                r = radix_tree_insert(&hspace->hprocs_mm_tree_root,
                                (unsigned long) new_hproc->mm, new_hproc);
                if (r)
                        goto unlock;

                r = radix_tree_insert(&heca_state->mm_tree_root,
                                (unsigned long) new_hproc->mm, new_hproc);
        }

unlock:
        spin_unlock(&heca_state->radix_lock);

        radix_tree_preload_end();
        if (r) {
                heca_printk(KERN_ERR "failed radix_tree_insert %d", r);
                radix_tree_delete(&hspace->hprocs_tree_root,
                                (unsigned long) new_hproc->hproc_id);
                if (is_hproc_local(new_hproc)) {
                        radix_tree_delete(&hspace->hprocs_mm_tree_root,
                                        (unsigned long) new_hproc->mm);
                        radix_tree_delete(&heca_state->mm_tree_root,
                                        (unsigned long) new_hproc->mm);
                }
        }

out:
        return r;
}

int create_hproc(struct hecaioc_hproc *hproc_info)
{
        struct heca_module_state *heca_state = get_heca_module_state();
        int r = 0;
        struct heca_space *hspace;
        struct heca_process *found_hproc, *new_hproc = NULL;

        /* allocate a new hproc */
        new_hproc = kzalloc(sizeof(*new_hproc), GFP_KERNEL);
        if (!new_hproc) {
                heca_printk(KERN_ERR "failed kzalloc");
                return -ENOMEM;
        }

        /* grab hspace lock */
        mutex_lock(&heca_state->heca_state_mutex);
        hspace = find_hspace(hproc_info->hspace_id);
        if (hspace)
                mutex_lock(&hspace->hspace_mutex);
        mutex_unlock(&heca_state->heca_state_mutex);
        if (!hspace) {
                heca_printk(KERN_ERR "could not find hspace: %d",
                                hproc_info->hspace_id);
                r = -EFAULT;
                goto no_hspace;
        }

        /* already exists? */
        found_hproc = find_hproc(hspace, hproc_info->hproc_id);
        if (found_hproc) {
                heca_printk(KERN_ERR "hproc %d (hspace %d) already exists",
                                hproc_info->hproc_id, hproc_info->hspace_id);
                r = -EEXIST;
                goto out;
        }

        /* initial hproc data */
        new_hproc->hproc_id = hproc_info->hproc_id;
        new_hproc->is_local = hproc_info->is_local;
        new_hproc->pid = hproc_info->pid;
        new_hproc->hspace = hspace;
        atomic_set(&new_hproc->refs, 2);

        /* register local hproc */
        if (hproc_info->is_local) {
                struct mm_struct *mm;

                mm = find_mm_by_pid(new_hproc->pid);
                if (!mm) {
                        heca_printk(KERN_ERR "can't find pid %d",
                                        new_hproc->pid);
                        r = -ESRCH;
                        goto out;
                }

                found_hproc = find_local_hproc_from_mm(mm);
                if (found_hproc) {
                        heca_printk(KERN_ERR "Hproc already exists for current process");
                        r = -EEXIST;
                        goto out;
                }

                new_hproc->mm = mm;
                new_hproc->hspace->nb_local_hprocs++;
                new_hproc->hmr_tree_root = RB_ROOT;
                seqlock_init(&new_hproc->hmr_seq_lock);
                new_hproc->hmr_cache = NULL;

                init_llist_head(&new_hproc->delayed_gup);
                INIT_DELAYED_WORK(&new_hproc->delayed_gup_work,
                                delayed_gup_work_fn);
                init_llist_head(&new_hproc->deferred_gups);
                INIT_WORK(&new_hproc->deferred_gup_work, deferred_gup_work_fn);

                spin_lock_init(&new_hproc->page_cache_spinlock);
                spin_lock_init(&new_hproc->page_readers_spinlock);
                spin_lock_init(&new_hproc->page_maintainers_spinlock);
                INIT_RADIX_TREE(&new_hproc->page_cache, GFP_ATOMIC);
                INIT_RADIX_TREE(&new_hproc->page_readers, GFP_ATOMIC);
                INIT_RADIX_TREE(&new_hproc->page_maintainers, GFP_ATOMIC);
                new_hproc->push_cache = RB_ROOT;
                seqlock_init(&new_hproc->push_cache_lock);
        }

        /* register hproc by id and mm_struct (must come before hspace_get_descriptor) */
        if (insert_hproc_to_radix_trees(heca_state, hspace, new_hproc))
                goto out;
        list_add(&new_hproc->hproc_ptr, &hspace->hprocs_list);

        /* assign descriptor for remote hproc */
        if (!is_hproc_local(new_hproc)) {
                u32 hproc_ids[] = {new_hproc->hproc_id, 0};
                new_hproc->descriptor = heca_get_descriptor(hspace->hspace_id,
                                hproc_ids);
        }

out:
        mutex_unlock(&hspace->hspace_mutex);
        if (found_hproc)
                release_hproc(found_hproc);

        if (r) {
                kfree(new_hproc);
                new_hproc = NULL;
                goto no_hspace;
        }

        if (!hproc_info->is_local) {
                r = connect_hproc(hproc_info->hspace_id, hproc_info->hproc_id,
                                hproc_info->remote.sin_addr.s_addr,
                                hproc_info->remote.sin_port);

                if (r) {
                        heca_printk(KERN_ERR "connect_hproc failed %d", r);
                        kfree(new_hproc);
                        new_hproc = NULL;
                }
        }
no_hspace:
        heca_printk(KERN_INFO "hproc %p, res %d, hspace_id %u, hproc_id: %u --> ret %d",
                        new_hproc, r, hproc_info->hspace_id,
                        hproc_info->hproc_id, r);
        return r;
}

inline void release_hproc(struct heca_process *hproc)
{
        atomic_dec(&hproc->refs);
        if (atomic_cmpxchg(&hproc->refs, 1, 0) == 1) {
                trace_heca_free_hproc(hproc->hproc_id);
                synchronize_rcu();
                kfree(hproc);
        }
}

/*
 * We dec page's refcount for every missing remote response (it would have
 * happened in hspace_ppe_clear_release after sending an answer to remote hproc)
 */
static void surrogate_push_remote_hproc(struct heca_process *hproc,
                struct heca_process *remote_hproc)
{
        struct rb_node *node;

        write_seqlock(&hproc->push_cache_lock);
        for (node = rb_first(&hproc->push_cache); node;) {
                struct heca_page_cache *hpc;
                int i;
                hpc = rb_entry(node, struct heca_page_cache, rb_node);
                node = rb_next(node);
                for (i = 0; i < hpc->hprocs.num; i++) {
                        if (hpc->hprocs.ids[i] == remote_hproc->hproc_id)
                                goto surrogate;
                }
                continue;

surrogate:
                if (likely(test_and_clear_bit(i, &hpc->bitmap))) {
                        page_cache_release(hpc->pages[0]);
                        atomic_dec(&hpc->nproc);
                        if (atomic_cmpxchg(&hpc->nproc, 1, 0) == 1 &&
                                        find_first_bit(&hpc->bitmap,
                                                hpc->hprocs.num) >=
                                        hpc->hprocs.num)
                                heca_push_cache_release(hpc->hproc, &hpc, 0);
                }
        }
        write_sequnlock(&hproc->push_cache_lock);
}

static void release_hproc_push_elements(struct heca_process *hproc)
{
        struct rb_node *node;

        write_seqlock(&hproc->push_cache_lock);
        for (node = rb_first(&hproc->push_cache); node;) {
                struct heca_page_cache *hpc;
                int i;

                hpc = rb_entry(node, struct heca_page_cache, rb_node);
                node = rb_next(node);
                /*
                 * dpc->hprocs has a pointer to the descriptor ids array, which already
                 * changed. we need to rely on the bitmap right now.
                 */
                for (i = 0; i < hpc->hprocs.num; i++) {
                        if (test_and_clear_bit(i, &hpc->bitmap))
                                page_cache_release(hpc->pages[0]);
                }
                heca_push_cache_release(hpc->hproc, &hpc, 0);
        }
        write_sequnlock(&hproc->push_cache_lock);
}

/*
 * pull ops tx_elements are only released after a response has returned.
 * therefore we can catch them and surrogate for them by iterating the tx
 * buffer.
 */
static void release_hproc_tx_elements(struct heca_process *hproc,
                struct heca_connection *conn)
{
        struct tx_buffer_element *tx_buf;
        int i;

        /* killed before it was first connected */
        if (!conn || !conn->tx_buffer.tx_buf)
                return;

        tx_buf = conn->tx_buffer.tx_buf;

        for (i = 0; i < conn->tx_buffer.len; i++) {
                struct tx_buffer_element *tx_e = &tx_buf[i];
                struct heca_message *msg = tx_e->hmsg_buffer;
                int types = MSG_REQ_PAGE | MSG_REQ_PAGE_TRY |
                        MSG_RES_PAGE_FAIL | MSG_REQ_READ;

                if (msg->type & types
                                && msg->hspace_id == hproc->hspace->hspace_id
                                && (msg->src_id == hproc->hproc_id
                                        || msg->dest_id == hproc->hproc_id)
                                && atomic_cmpxchg(&tx_e->used, 1, 2) == 1) {
                        struct heca_page_cache *dpc = tx_e->wrk_req->hpc;

                        heca_pull_req_failure(dpc);
                        tx_e->wrk_req->dst_addr->mem_page = NULL;
                        heca_release_pull_hpc(&dpc);
                        heca_ppe_clear_release(conn, &tx_e->wrk_req->dst_addr);

                        /* rdma processing already finished, we have to release ourselves */
                        smp_mb();
                        if (atomic_read(&tx_e->used) > 2)
                                try_release_tx_element(conn, tx_e);
                }
        }
}

static void release_hproc_queued_requests(struct heca_process *hproc,
                struct tx_buffer *tx)
{
        struct heca_request *req, *n;
        u32 hproc_id = hproc->hproc_id;

        mutex_lock(&tx->flush_mutex);
        heca_request_queue_merge(tx);
        list_for_each_entry_safe (req, n,
                        &tx->ordered_request_queue, ordered_list){
                if (req->remote_hproc_id == hproc_id ||
                                req->local_hproc_id == hproc_id) {
                        list_del(&req->ordered_list);
                        if (req->hpc && req->hpc->tag == PULL_TAG)
                                heca_release_pull_hpc(&req->hpc);
                        release_heca_request(req);
                }
        }
        mutex_unlock(&tx->flush_mutex);
}

void remove_hproc(u32 hspace_id, u32 hproc_id)
{
        struct heca_module_state *heca_state = get_heca_module_state();
        struct heca_space *hspace;
        struct heca_process *hproc = NULL;

        mutex_lock(&heca_state->heca_state_mutex);
        hspace = find_hspace(hspace_id);
        if (!hspace) {
                mutex_unlock(&heca_state->heca_state_mutex);
                return;
        }

        mutex_lock(&hspace->hspace_mutex);
        hproc = find_hproc(hspace, hproc_id);
        if (!hproc) {
                mutex_unlock(&heca_state->heca_state_mutex);
                goto out;
        }
        if (is_hproc_local(hproc)) {
                radix_tree_delete(&get_heca_module_state()->mm_tree_root,
                                (unsigned long) hproc->mm);
        }
        mutex_unlock(&heca_state->heca_state_mutex);

        list_del(&hproc->hproc_ptr);
        radix_tree_delete(&hspace->hprocs_tree_root,
                        (unsigned long) hproc->hproc_id);
        if (is_hproc_local(hproc)) {
                cancel_delayed_work_sync(&hproc->delayed_gup_work);
                // to make sure everything is clean
                dequeue_and_gup_cleanup(hproc);
                hspace->nb_local_hprocs--;
                radix_tree_delete(&hspace->hprocs_mm_tree_root,
                                (unsigned long) hproc->mm);
        }

        remove_hproc_from_descriptors(hproc);

        /*
         * we removed the hproc from all descriptors and trees, so we won't make any
         * new operations concerning it. now we only have to make sure to cancel
         * all pending operations involving this hproc, and it will be safe to remove
         * it.
         *
         * we cannot actually hold until every operation is complete, so we rely on
         * refcounting. and yet we try to catch every operation, and be a surrogate
         * for it, if possible; otherwise we just trust it to drop the refcount when
         * it finishes. the main point is catching all operations, not leaving
         * anything unattended (thus creating a resource leak).
         *
         * we catch all pending operations using (by order) the queued requests
         * lists, the tx elements buffers, and the push caches of hprocs.
         *
         * FIXME: what about pull operations, in which we remove_hproc() after
         * find_hproc(), but before tx_hspace_send()??? We can't disable preemption
         * there, but we might lookup_hproc() after we send, and handle the case in
         * which it isn't!
         * FIXME: the same problem is valid for push operations!
         */
        if (is_hproc_local(hproc)) {
                struct rb_root *root;
                struct rb_node *node;

                if (heca_state->hcm) {
                        root = &heca_state->hcm->connections_rb_tree_root;
                        for (node = rb_first(root);
                                        node; node = rb_next(node)) {
                                struct heca_connection *conn;

                                conn = rb_entry(node,
                                                struct heca_connection,
                                                rb_node);
                                BUG_ON(!conn);
                                release_hproc_queued_requests(hproc,
                                                &conn->tx_buffer);
                                release_hproc_tx_elements(hproc, conn);
                        }
                }
                release_hproc_push_elements(hproc);
                destroy_hproc_mrs(hproc);
        } else if (hproc->connection) {
                struct heca_process *local_hproc;

                release_hproc_queued_requests(hproc,
                                &hproc->connection->tx_buffer);
                release_hproc_tx_elements(hproc, hproc->connection);

                /* potentially very expensive way to do this */
                list_for_each_entry (local_hproc, &hproc->hspace->hprocs_list,
                                hproc_ptr) {
                        if (is_hproc_local(local_hproc))
                                surrogate_push_remote_hproc(local_hproc, hproc);
                }
        }

        atomic_dec(&hproc->refs);
        release_hproc(hproc);

out:
        mutex_unlock(&hspace->hspace_mutex);
}

struct heca_process *find_any_hproc(struct heca_space *hspace,
                struct heca_process_list hprocs)
{
        int i;
        struct heca_process *hproc;

        for_each_valid_hproc(hprocs, i) {
                hproc = find_hproc(hspace, hprocs.ids[i]);
                if (likely(hproc))
                        return hproc;
        }

        return NULL;
}


static void destroy_hproc_mrs(struct heca_process *hproc)
{
        struct rb_root *root = &hproc->hmr_tree_root;

        do {
                struct heca_memory_region *mr;
                struct rb_node *node;

                write_seqlock(&hproc->hmr_seq_lock);
                node = rb_first(root);
                if (!node) {
                        write_sequnlock(&hproc->hmr_seq_lock);
                        break;
                }
                mr = rb_entry(node, struct heca_memory_region, rb_node);
                rb_erase(&mr->rb_node, root);
                write_sequnlock(&hproc->hmr_seq_lock);
                heca_printk(KERN_INFO "removing hspace_id: %u hproc_id: %u, mr_id: %u",
                                hproc->hspace->hspace_id, hproc->hproc_id,
                                mr->hmr_id);
                synchronize_rcu();
                kfree(mr);
        } while(1);
}

struct heca_process *find_local_hproc_from_list(
                struct heca_space *hspace)
{
        struct heca_process *tmp_hproc;

        list_for_each_entry (tmp_hproc, &hspace->hprocs_list, hproc_ptr) {
                if (!is_hproc_local(tmp_hproc))
                        continue;
                heca_printk(KERN_DEBUG "hspace %d local hproc is %d",
                                hspace->hspace_id, tmp_hproc->hproc_id);
                grab_hproc(tmp_hproc);
                return tmp_hproc;
        }
        return NULL;
}
